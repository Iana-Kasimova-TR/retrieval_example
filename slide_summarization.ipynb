{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9b51b52c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240030"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([count_tokens(str(s)) for s in soup.find_all(\"div\", {\"class\": \"slide\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "29f19e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.73296"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_length = np.array([count_tokens(str(s)) for s in soup.find_all(\"div\", {\"class\": \"slide\"})])\n",
    "gpt_3_mask = token_length < 4096\n",
    "gpt_4_mask = (token_length > 4096) * (token_length < 8192)\n",
    "gpt_4_32_mask = (token_length > 8192)\n",
    "\n",
    "assert token_length[gpt_3_mask].shape[0] + token_length[gpt_4_mask].shape[0] + token_length[gpt_4_32_mask].shape[0] == token_length.shape[0]\n",
    "\n",
    "((sum(token_length[gpt_3_mask])/1000*0.003) \\\n",
    "+ (sum(token_length[gpt_4_mask])/1000*0.04) \\\n",
    "+ (sum(token_length[gpt_4_32_mask])/1000*0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9715364b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_length[gpt_4_32_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ebf8e125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.56112"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(token_length[gpt_4_32_mask])/1000*0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f85caa",
   "metadata": {},
   "source": [
    "# Slides summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c725e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "# import fitz\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import warnings\n",
    "import contextlib\n",
    "import requests\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "import glob\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "old_merge_environment_settings = requests.Session.merge_environment_settings\n",
    "\n",
    "token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9ad5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"count the number of tokens in a string\"\"\"\n",
    "    return len(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3e00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"./epam_offerings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a18ff3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./epam_offerings/DASO_Service+Offerings+review+session-20220907_Product+Support_short/Product+Support_short.html',\n",
       " './epam_offerings/DASO_Service+Offerings+review+session-20221005_Optimization+Products_short/Optimization+Products_short.html',\n",
       " './epam_offerings/DASO_Service+Offerings+review+session-20221012_Operational+Intelligence_short/Operational+Intelligence_short.html',\n",
       " './epam_offerings/DASO_Service+Offerings+review+sessions-20220413_Data+Governance_short/Data+Governance_short.html',\n",
       " './epam_offerings/DASO_Service+Offerings+review+sessions-20220420_Fast+Data_short/Fast+Data_short.html',\n",
       " './epam_offerings/DASO_Service+Offerings+review+sessions-20220427_Data+quality_short/Data+quality_short.html',\n",
       " './epam_offerings/DASO_Service+Offerings+review+sessions-20220518_RGM_short/RGM_short.html',\n",
       " './epam_offerings/DASO_Service+Offerings+review+sessions-20220608_Computer+vision_short/Computer+vision_short.html']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob(f\"{DATA_FOLDER}*/*_short.html\")\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb45673",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def no_ssl_verification():\n",
    "    opened_adapters = set()\n",
    "\n",
    "    def merge_environment_settings(self, url, proxies, stream, verify, cert):\n",
    "        # Verification happens only once per connection so we need to close\n",
    "        # all the opened adapters once we're done. Otherwise, the effects of\n",
    "        # verify=False persist beyond the end of this context manager.\n",
    "        opened_adapters.add(self.get_adapter(url))\n",
    "\n",
    "        settings = old_merge_environment_settings(self, url, proxies, stream, verify, cert)\n",
    "        settings['verify'] = False\n",
    "\n",
    "        return settings\n",
    "\n",
    "    requests.Session.merge_environment_settings = merge_environment_settings\n",
    "\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', InsecureRequestWarning)\n",
    "            yield\n",
    "    finally:\n",
    "        requests.Session.merge_environment_settings = old_merge_environment_settings\n",
    "\n",
    "        for adapter in opened_adapters:\n",
    "            try:\n",
    "                adapter.close()\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ca45d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpXwKghwlw4mI8hFn39alhrFUBxbGZRltf4VcpB5dkdt5Gsv3I375ZqGN7AWwF4NPYlXQ4SxGPYMPlkEr7XOlg1sX5\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openai.lab.epam.com/v1\"\n",
    "import openai\n",
    "\n",
    "with no_ssl_verification():\n",
    "\n",
    "    openai.api_key = token\n",
    "    print(openai.api_key)\n",
    "\n",
    "    engines = openai.Engine.list()\n",
    "    print(engines.data[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b753bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prompt(prompt: str):\n",
    "    with no_ssl_verification():\n",
    "        res = openai.Completion.create(prompt=prompt,\n",
    "                                       temperature=0,\n",
    "                                       max_tokens=300,\n",
    "                                       model=\"text-davinci-003\"\n",
    "                                       )[\"choices\"][0][\"text\"].strip(\" \\n\")\n",
    "        return res\n",
    "def test_prompt_gpt_4(prompt: str):    \n",
    "    res = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\", # \"gpt-3.5-turbo\" \"gpt-4\"\n",
    "      messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    res = res[\"choices\"][0][\"message\"][\"content\"].strip(\" \\n\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a646869",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/INTAKE_copy_cleaned.html\"\n",
    "with open(filename, \"r\") as f:\n",
    "    data = f.read()\n",
    "soup = BeautifulSoup(data, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a81c81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/INTAKE_copy_cleaned.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df9b7d49",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4118 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([count_tokens(str(s)) for s in soup.find_all(\"div\", {\"class\": \"slide\"})], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46fc910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_slide(slide):\n",
    "\n",
    "    prompt = f\"Q:Give the slide a title and summarize main points of the slide in a detailed way, preserve the structure, include all mentioned approaches and tools\\nSlide:\\n{str(slide)}\\n\\nA:\"\n",
    "    \n",
    "    output = test_prompt_gpt_4(prompt)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b813cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "slide = str(soup.find_all(\"div\", {\"class\": \"slide\"})[i])\n",
    "out = summarize_slide(slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85b1d7a6-e96c-41f3-a80e-658ec19bad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unified Product Governance Planning - Intake (Continued)\n",
      "\n",
      "Main Points:\n",
      "1. Initial Requirements Gathering\n",
      "   - Deep dive functional sessions (Q&A, whiteboarding, etc.)\n",
      "   - Analyze existing Epic & User Story Backlog\n",
      "   - Personas & User Journey analysis\n",
      "   - Platforms issues & non-functional requirements gathering\n",
      "\n",
      "2. Product Backlog Composition & Clarification\n",
      "   - Structuring Functional model of the current state to the Product backlog\n",
      "   - Applying product concept\n",
      "   - Incorporating new asks from business\n",
      "   - Processing insights from customer feedbacks\n",
      "   - Developing recommendations\n",
      "   - Adding opportunities from competition analysis\n",
      "   - Mapping functional capabilities to the new User journeys & filling the gaps\n",
      "\n",
      "3. Backlog Prioritization & Roadmapping\n",
      "   - Functionality prioritization, based on the business needs & value\n",
      "   - Definition of the key User journeys to start migration from\n",
      "   - Functional roadmap definition (as a part of transition plan)\n",
      "   - UX prototype alignment\n",
      "   - Technical dependencies definition\n",
      "\n",
      "4. MVP Planning\n",
      "   - MVP Technical feasibility estimation\n",
      "   - MVP milestones & dependencies alignment\n",
      "   - MVP scope finalization & agreement\n",
      "   - MVP budget & timings planning\n",
      "   - Product capabilities roadmap definition\n",
      "\n",
      "5. Sprint 1 Design\n",
      "   - Sprint 1 planning\n",
      "   - Sprint 1 UI designing\n",
      "   - Sprint 1 User stories specification with acceptance criteria compliant to Definition of Ready\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c353a-ab2d-44cc-90c7-03bc6b61393b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d098b4a-4757-4b3f-a496-f30994a768df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e38aaae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:26,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [02:23,  6.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# res = {}\n",
    "for i, slide in tqdm(enumerate(soup.find_all(\"div\", {\"class\": \"slide\"})), leave=True):\n",
    "    if i+1 not in res:\n",
    "        try:\n",
    "            out = summarize_slide(slide)\n",
    "            res[i+1] = out\n",
    "        except:\n",
    "            print(i)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b6401445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12364"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=7\n",
    "count_tokens(str(soup.find_all(\"div\", {\"class\": \"slide\"})[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3b20329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide = str(soup.find_all(\"div\", {\"class\": \"slide\"})[i])\n",
    "out_1 = summarize_slide(slide[:int(len(slide)/2)])\n",
    "out_2 = summarize_slide(slide[int(len(slide)/2):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2692e57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: We Cover the Full Lifecycle of Computer Vision Projects\n",
      "\n",
      "Summary: \n",
      "This slide highlights the full lifecycle of computer vision projects, covering every phase from discovery to evolution or hand-over. The various phases include Discovery (1-2 weeks), POC and/or MVP (2-6 months), Development (3+ months), Testing and Deployment (3+ months), and Evolution or Hand-over. Each phase comes with its specific objectives and deliverables. Key approaches and tools involved in each step are outlined, ensuring a comprehensive understanding of the entire process.\n",
      "\n",
      "Title: Change Management Framework for Data-Driven Solutions\n",
      "\n",
      "Main Points:\n",
      "\n",
      "1. Implement the Data Pipeline\n",
      "   - Create a reliable data pipeline to collect and process data\n",
      "\n",
      "2. Refine and Extend the Datasets\n",
      "   - Continuously improve dataset quality by refining and extending data sources\n",
      "\n",
      "3. Implement the Model and Run QA Tests\n",
      "   - Develop the machine learning model and execute quality assurance tests to ensure optimal performance\n",
      "\n",
      "4. Develop CV Workflow Automation\n",
      "   - Automate computer vision workflows for seamless integration in data processing pipelines\n",
      "\n",
      "5. Perform Ongoing AB Testing and Iterative Model Improvement\n",
      "   - Conduct continuous AB tests and incrementally refine the model based on performance and feedback\n",
      "\n",
      "6. Establish QA Process\n",
      "   - Implement a rigorous quality assurance process to maintain the model's performance\n",
      "\n",
      "7. Integrate the Model with Existing Staging and Production Environments\n",
      "   - Seamlessly integrate the model with existing infrastructure for a smooth transition\n",
      "\n",
      "8. Perform Ongoing AB Testing and Application Maintenance\n",
      "   - Continuously monitor the model's performance and make necessary updates to ensure it remains relevant and useful\n",
      "\n",
      "9. Maintain Model and Complete Knowledge Transfer\n",
      "   - Keep the model up-to-date and ensure all stakeholders understand its functionality and use-cases\n",
      "\n",
      "10. Improve Quality with Human-In-The-Loop Approach\n",
      "    - Leverage human expertise to improve model accuracy, incorporating user feedback into model training and refinement\n",
      "\n",
      "11. Team Roles\n",
      "    - Solution Architect, Senior Data Scientist, Industry SME, Delivery Manager, Content/Labeling Specialist, Developers, DevOps Engineers, Data Engineers, Test Engineers\n",
      "\n",
      "12. Tools\n",
      "    - Utilize a diverse set of tools and technologies to develop and maintain the data-driven solution\n"
     ]
    }
   ],
   "source": [
    "print(out_1)\n",
    "print()\n",
    "print(out_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f6d58233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: We Cover the Full Lifecycle of Computer Vision Projects\\n\\nSummary: \\nThis slide highlights the full lifecycle of computer vision projects, covering every phase from discovery to evolution or hand-over. The various phases include Discovery (1-2 weeks), POC and/or MVP (2-6 months), Development (3+ months), Testing and Deployment (3+ months), and Evolution or Hand-over. Each phase comes with its specific objectives and deliverables. Key approaches and tools involved in each step are outlined, ensuring a comprehensive understanding of the entire process.'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3ff217ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Title: Change Management Framework for Data-Driven Solutions\\n\\nMain Points:\\n\\n1. Implement the Data Pipeline\\n   - Create a reliable data pipeline to collect and process data\\n\\n2. Refine and Extend the Datasets\\n   - Continuously improve dataset quality by refining and extending data sources\\n\\n3. Implement the Model and Run QA Tests\\n   - Develop the machine learning model and execute quality assurance tests to ensure optimal performance\\n\\n4. Develop CV Workflow Automation\\n   - Automate computer vision workflows for seamless integration in data processing pipelines\\n\\n5. Perform Ongoing AB Testing and Iterative Model Improvement\\n   - Conduct continuous AB tests and incrementally refine the model based on performance and feedback\\n\\n6. Establish QA Process\\n   - Implement a rigorous quality assurance process to maintain the model's performance\\n\\n7. Integrate the Model with Existing Staging and Production Environments\\n   - Seamlessly integrate the model with existing infrastructure for a smooth transition\\n\\n8. Perform Ongoing AB Testing and Application Maintenance\\n   - Continuously monitor the model's performance and make necessary updates to ensure it remains relevant and useful\\n\\n9. Maintain Model and Complete Knowledge Transfer\\n   - Keep the model up-to-date and ensure all stakeholders understand its functionality and use-cases\\n\\n10. Improve Quality with Human-In-The-Loop Approach\\n    - Leverage human expertise to improve model accuracy, incorporating user feedback into model training and refinement\\n\\n11. Team Roles\\n    - Solution Architect, Senior Data Scientist, Industry SME, Delivery Manager, Content/Labeling Specialist, Developers, DevOps Engineers, Data Engineers, Test Engineers\\n\\n12. Tools\\n    - Utilize a diverse set of tools and technologies to develop and maintain the data-driven solution\""
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "43735ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"\"\"Title: We Cover the Full Lifecycle of Computer Vision Projects\\n\\nSummary: \\nThis slide highlights the full lifecycle of computer vision projects, covering every phase from discovery to evolution or hand-over. The various phases include Discovery (1-2 weeks), POC and/or MVP (2-6 months), Development (3+ months), Testing and Deployment (3+ months), and Evolution or Hand-over. Each phase comes with its specific objectives and deliverables. Key approaches and tools involved in each step are outlined, ensuring a comprehensive understanding of the entire process.\\n\\nMain Points:\\n\\n1. Implement the Data Pipeline\\n   - Create a reliable data pipeline to collect and process data\\n\\n2. Refine and Extend the Datasets\\n   - Continuously improve dataset quality by refining and extending data sources\\n\\n3. Implement the Model and Run QA Tests\\n   - Develop the machine learning model and execute quality assurance tests to ensure optimal performance\\n\\n4. Develop CV Workflow Automation\\n   - Automate computer vision workflows for seamless integration in data processing pipelines\\n\\n5. Perform Ongoing AB Testing and Iterative Model Improvement\\n   - Conduct continuous AB tests and incrementally refine the model based on performance and feedback\\n\\n6. Establish QA Process\\n   - Implement a rigorous quality assurance process to maintain the model's performance\\n\\n7. Integrate the Model with Existing Staging and Production Environments\\n   - Seamlessly integrate the model with existing infrastructure for a smooth transition\\n\\n8. Perform Ongoing AB Testing and Application Maintenance\\n   - Continuously monitor the model's performance and make necessary updates to ensure it remains relevant and useful\\n\\n9. Maintain Model and Complete Knowledge Transfer\\n   - Keep the model up-to-date and ensure all stakeholders understand its functionality and use-cases\\n\\n10. Improve Quality with Human-In-The-Loop Approach\\n    - Leverage human expertise to improve model accuracy, incorporating user feedback into model training and refinement\\n\\n11. Team Roles\\n    - Solution Architect, Senior Data Scientist, Industry SME, Delivery Manager, Content/Labeling Specialist, Developers, DevOps Engineers, Data Engineers, Test Engineers\\n\\n12. Tools\\n    - Utilize a diverse set of tools and technologies to develop and maintain the data-driven solution\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "63d230ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: We Cover the Full Lifecycle of Computer Vision Projects\n",
      "\n",
      "Summary: \n",
      "This slide highlights the full lifecycle of computer vision projects, covering every phase from discovery to evolution or hand-over. The various phases include Discovery (1-2 weeks), POC and/or MVP (2-6 months), Development (3+ months), Testing and Deployment (3+ months), and Evolution or Hand-over. Each phase comes with its specific objectives and deliverables. Key approaches and tools involved in each step are outlined, ensuring a comprehensive understanding of the entire process.\n",
      "\n",
      "Main Points:\n",
      "\n",
      "1. Implement the Data Pipeline\n",
      "   - Create a reliable data pipeline to collect and process data\n",
      "\n",
      "2. Refine and Extend the Datasets\n",
      "   - Continuously improve dataset quality by refining and extending data sources\n",
      "\n",
      "3. Implement the Model and Run QA Tests\n",
      "   - Develop the machine learning model and execute quality assurance tests to ensure optimal performance\n",
      "\n",
      "4. Develop CV Workflow Automation\n",
      "   - Automate computer vision workflows for seamless integration in data processing pipelines\n",
      "\n",
      "5. Perform Ongoing AB Testing and Iterative Model Improvement\n",
      "   - Conduct continuous AB tests and incrementally refine the model based on performance and feedback\n",
      "\n",
      "6. Establish QA Process\n",
      "   - Implement a rigorous quality assurance process to maintain the model's performance\n",
      "\n",
      "7. Integrate the Model with Existing Staging and Production Environments\n",
      "   - Seamlessly integrate the model with existing infrastructure for a smooth transition\n",
      "\n",
      "8. Perform Ongoing AB Testing and Application Maintenance\n",
      "   - Continuously monitor the model's performance and make necessary updates to ensure it remains relevant and useful\n",
      "\n",
      "9. Maintain Model and Complete Knowledge Transfer\n",
      "   - Keep the model up-to-date and ensure all stakeholders understand its functionality and use-cases\n",
      "\n",
      "10. Improve Quality with Human-In-The-Loop Approach\n",
      "    - Leverage human expertise to improve model accuracy, incorporating user feedback into model training and refinement\n",
      "\n",
      "11. Team Roles\n",
      "    - Solution Architect, Senior Data Scientist, Industry SME, Delivery Manager, Content/Labeling Specialist, Developers, DevOps Engineers, Data Engineers, Test Engineers\n",
      "\n",
      "12. Tools\n",
      "    - Utilize a diverse set of tools and technologies to develop and maintain the data-driven solution\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "92009a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fd3defcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[i+1] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "51a62190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(filename.replace(\"_short.html\", \"_summary.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b05cde6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(filename.replace(\"_short.html\", \"_summary.pkl\"), \"rb\") as f:\n",
    "    check = pickle.load(f)\n",
    "check == res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "58a48417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([2, 3, 6, 7, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 1, 4, 5, 11, 16])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "a4e54744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./epam_offerings/DASO_Service+Offerings+review+sessions-20220608_Computer+vision_short/Computer+vision_short.html'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e6fca25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filenames[7]\n",
    "with open(filename, \"r\") as f:\n",
    "    data = f.read()\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    \n",
    "with open(filename.replace(\"_short.html\", \"_summary.pkl\"), \"rb\") as f:\n",
    "    check = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "a5f8bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = dict(sorted(check.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d6839828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (10, 8), (11, 9), (12, 10), (13, 11), (14, 12), (15, 13), (16, 14), (18, 15), (19, 16), (20, 17), (21, 18), (22, 19), (23, 20), (24, 21)]\n"
     ]
    }
   ],
   "source": [
    "real_slide_nums = [int(re.findall(\"\\d{1,2}$\", el[\"id\"])[0]) for el in soup.find_all(\"div\", {\"class\": \"slide\"})]\n",
    "real_slide_nums = np.array(real_slide_nums)[np.array(list(check.keys())) - 1].tolist()\n",
    "if not (real_slide_nums == list(check.keys())):\n",
    "    print(list(zip(real_slide_nums, list(check.keys()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5b9373d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(check) == len(real_slide_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "03758e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = {true_n: v for (k, v), true_n in zip(check.items(), real_slide_nums)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "4cce3998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(real_slide_nums == list(corrected.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "aabe40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename.replace(\"_short.html\", \"_summary_corrected.pkl\"), \"wb\") as f:\n",
    "     pickle.dump(corrected, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178ce1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e8260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4213e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full Lifecycle of Computer Vision Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37038a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
